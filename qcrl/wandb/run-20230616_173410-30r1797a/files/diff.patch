diff --git a/qcrl/ppo.py b/qcrl/ppo.py
index a04c443..441ca16 100644
--- a/qcrl/ppo.py
+++ b/qcrl/ppo.py
@@ -5,6 +5,7 @@ import random
 from tqdm import tqdm
 from distutils.util import strtobool
 
+from jax import config
 import numpy as np
 
 import torch
@@ -16,7 +17,9 @@ from torch.utils.tensorboard import SummaryWriter
 from torchinfo import summary
 import wandb
 
-from .readout_optimisation.rl_envs.gymnasium_env import ReadoutEnv
+from readout_optimisation.rl_envs.resonator_environment import ResonatorEnv
+
+config.update("jax_enable_x64", True)
 
 # For debugging
 # torch.autograd.set_detect_anomaly(True)
@@ -83,7 +86,7 @@ def layer_init(layer, std=np.sqrt(2), bias_const=0.0):
 class CombinedAgent(nn.Module):
     def __init__(self, env):
         super(CombinedAgent, self).__init__()
-        self.n_layers = 128
+        self.n_layers = 256
         self.linear1 = layer_init(
             nn.Linear(env.observation_space.shape[0], self.n_layers)
         )
@@ -138,7 +141,7 @@ if __name__ == "__main__":
     device = torch.device("cuda" if torch.cuda.is_available() and args.cuda else "cpu")
 
     assert args.env_id == "arthur_env", f"env_id must be arthur_env"
-    env = ReadoutEnv()
+    env = ResonatorEnv()
     next_obs, info = env.reset(seed=args.seed)
 
     model = CombinedAgent(env).to(device)
@@ -153,6 +156,9 @@ if __name__ == "__main__":
         (args.batch_size,) + env.observation_space.shape, requires_grad=True
     ).to(device)
 
+    print(f"env action space shape: {env.action_space.shape}")
+    print(f"env observation space shape: {env.observation_space.shape}")
+
     # Start the Environment
     start_time = time.time()
     next_obs, _ = env.reset(seed=args.seed)
@@ -199,10 +205,12 @@ if __name__ == "__main__":
         optimizer.step()
 
         if args.track:
-            writer.add_scalar("charts/mean_reward", info["mean rewards"], update)
-            writer.add_scalar(
-                "charts/average_fidelity", info["average fidelity"], update
-            )
+            writer.add_scalar("charts/mean_reward", info["mean reward"], update)
+            writer.add_scalar("charts/mean_reward", info["mean max photon"], update)
+            writer.add_scalar("charts/mean_reward", info["mean max separation"], update)
+            # writer.add_scalar(
+            #    "charts/average_fidelity", info["average fidelity"], update
+            # )
             writer.add_scalar(
                 "charts/advantage", advantages.detach().mean().numpy(), update
             )
@@ -223,9 +231,16 @@ if __name__ == "__main__":
 
         if args.print_debug:
             print("\n Update", update)
-            print("Average reward", info["mean rewards"])
-            print("Average Gate Fidelity:", info["average fidelity"])
-            print("Max Reward", info["max reward"])
-            print("Max Fidelity", info["max fidelity"])
+            print("Average reward per Update: ", info["mean reward"])
+            print("Average max photon per Update: ", info["mean max photon"])
+            print("Average max separation per Update: ", info["mean max separation"])
+            print("Max Reward till now:", info["max reward"])
+            print("Separation at Max Reward:", info["separation at max reward"])
+            print("Photon at Max Reward:", info["photon at max reward"])
+            print("Max Separation till now", info["max separation"])
+            # print("Average Gate Fidelity:", info["average fidelity"])
+            # print("Max Reward", info["max reward"])
+            # print("Max Fidelity", info["max fidelity"])
 
-    writer.close()
+    if args.track:
+        writer.close()
diff --git a/qcrl/readout_optimisation/rl_envs/temp.py b/qcrl/readout_optimisation/rl_envs/temp.py
index b74ccf8..4b9e5c5 100644
--- a/qcrl/readout_optimisation/rl_envs/temp.py
+++ b/qcrl/readout_optimisation/rl_envs/temp.py
@@ -1,9 +1,47 @@
-import numpy as np
-from gymnasium_env import ReadoutEnv
-
-env = ReadoutEnv()
-obs, info = env.reset()
-action = np.arange(0.0, env.action_space.shape[0], 1)
-print(action)
-next_obs, reward, done, _, info = env.step(action)
-print(next_obs)
+from jax import config
+import jax.numpy as jnp
+from resonator_environment import ResonatorEnv
+
+config.update("jax_enable_x64", True)
+
+float_dtype = jnp.float64
+
+T0 = 0.0
+T1 = 2.0
+NUM_ACTION = 51
+TS_ACTION = jnp.linspace(T0, T1, NUM_ACTION, dtype=float_dtype)
+
+RES_DRIVE_AMP = 0.5
+GAUSSIAN_MEAN = 0.5 * T1
+GAUSSIAN_STD = 0.25 * T1
+
+BATCH_SIZE = 100
+
+single_gaussian_complex = jnp.asarray(
+    (
+        RES_DRIVE_AMP
+        * jnp.exp(-((TS_ACTION - GAUSSIAN_MEAN) ** 2) / (2 * GAUSSIAN_STD**2))
+    ),
+    dtype=float_dtype,
+)
+
+single_gaussian_real = single_gaussian_complex.real
+single_gaussian_imag = single_gaussian_complex.imag
+single_res_state = jnp.array([0.0, 0.0], dtype=float_dtype)
+
+single_composite_action = jnp.concatenate(
+    (single_gaussian_real, single_gaussian_imag, single_res_state)
+).reshape(1, 2 * (NUM_ACTION + 1))
+
+batched_composite_action = single_composite_action
+
+for i in range(BATCH_SIZE - 1):
+    batched_composite_action = jnp.concatenate(
+        (batched_composite_action, single_composite_action), dtype=float_dtype
+    )
+
+
+env = ResonatorEnv()
+observation, info = env.reset()
+obs, reward, done, _, info = env.step(batched_composite_action)
+print(info)
diff --git a/qcrl/readout_optimisation/simulations/C_states_sim.py b/qcrl/readout_optimisation/simulations/C_states_sim.py
index 33f5126..9360f2f 100644
--- a/qcrl/readout_optimisation/simulations/C_states_sim.py
+++ b/qcrl/readout_optimisation/simulations/C_states_sim.py
@@ -69,7 +69,7 @@ if __name__ == "__main__":
     res_drive_amp = 2.5  # * t_pi
     trans_drive_amp = 0 * res_drive_amp * SIN_ANGLE
 
-    RES_COMPLEX_STATE = -1j * 2.7
+    RES_COMPLEX_STATE = -1j * 2.24
     res_state_imag = RES_COMPLEX_STATE.imag
 
     drive_on_res_gaussian = jnp.asarray(
@@ -300,7 +300,7 @@ if __name__ == "__main__":
     )
 
     fig, ax = plt.subplots(1, num=f"C Separation, Init State: {RES_COMPLEX_STATE}")
-    ax.plot(TS_SIM, separation, label="separation", color="blue")
+    ax.plot(TS_SIM, separation, label=f"max separation: {max_separation}", color="blue")
     ax.plot(
         time_of_max_sep,
         max_separation,
diff --git a/qcrl/readout_optimisation/simulations/__pycache__/updated_utils.cpython-39.pyc b/qcrl/readout_optimisation/simulations/__pycache__/updated_utils.cpython-39.pyc
index 1244096..d08720f 100644
Binary files a/qcrl/readout_optimisation/simulations/__pycache__/updated_utils.cpython-39.pyc and b/qcrl/readout_optimisation/simulations/__pycache__/updated_utils.cpython-39.pyc differ
diff --git a/qcrl/readout_optimisation/simulations/updated_utils.py b/qcrl/readout_optimisation/simulations/updated_utils.py
index 8952356..fcf7117 100644
--- a/qcrl/readout_optimisation/simulations/updated_utils.py
+++ b/qcrl/readout_optimisation/simulations/updated_utils.py
@@ -1,6 +1,8 @@
 import time
 import jax.numpy as jnp
 import matplotlib.pyplot as plt
+from jaxtyping import Array
+from jax.experimental import sparse
 
 
 def complex_plotter(ts, complex_1, complex_2, rot_1, rot_2, name_1, name_2, fig_name):
@@ -98,7 +100,7 @@ def simple_plotter_debug(ts, complex_1, complex_2, name_1, name_2, fig_name):
     return fig, ax
 
 
-t_pi = 2.0 * jnp.pi
+t_pi = 1.0  # 2.0 * jnp.pi
 
 CHI = 0.16 * 5.35 * t_pi
 KAPPA = CHI
@@ -106,7 +108,7 @@ G = 102.9 * t_pi
 WA = 7062.0 * t_pi
 WB = 5092.0 * t_pi
 DELTA = WA - WB
-GAMMA = 1 / 39.2
+GAMMA = 1 / 39.2 * t_pi
 KERR = CHI * 0.5 * (G / DELTA) ** 2
 ANHARM = 0.5 * CHI / (G / DELTA) ** 2
 SQRT_RATIO = jnp.sqrt(2.0 / 62.5)
@@ -172,7 +174,7 @@ def get_params(print_params=True):
         "chi": CHI,
         "chi_eff": CHI_EFF,
         "delta_eff": DELTA_EFF,
-        'kappa_eff': KAPPA_EFF,
+        "kappa_eff": KAPPA_EFF,
     }
 
     if print_params:
@@ -181,3 +183,104 @@ def get_params(print_params=True):
             print(f"{key}: {value}")
 
     return physics_params
+
+
+def dagger(input):
+    return jnp.conjugate(input).T
+
+
+def state2dm(state: Array):
+    """
+    Takes an input state (bra or ket) and outputs a Density Matrix formed from the Outer Product.
+
+    Input:
+    State -> Jax 2D Array
+
+    Let N be the dimensions of the state, a ket should have shape (N, 1) and a bra should have shape (1, N), where N >= 2
+    """
+    state_type = "ket"
+    if len(state.shape) != 2:
+        raise ValueError(
+            "Ensure the state is a 2D array with shape (N, 1) for a ket, or (1, N) for a bra"
+        )
+
+    if state.shape[0] == 1:
+        state_type = "bra"
+    elif state.shape[1] == 1:
+        state_type = "ket"
+    else:
+        raise ValueError(
+            "At least one of the dimensions of the state must be of length greater than 1"
+        )
+
+    if state_type == "ket":
+        dm = state * dagger(state)
+    if state_type == "bra":
+        dm = dagger(state) * state
+    return dm
+
+
+def number_op(N, dtype=jnp.complex64, use_sparse=True):
+    """
+    Makes a diagonal matrix representation of the number operator
+    By default uses jnp.complex64 as the dtype (a jax compatible dtype must be passed)
+    By default use_sparse = True, so a sparse Jax array is made. If sparse = False, the dense representation is made instead.
+    """
+    if not isinstance(N, int):
+        raise ValueError("N must be of int type and non-zero")
+
+    out_matrix = jnp.diag(jnp.arange(0, N, dtype=dtype), k=0)
+    if use_sparse:
+        out_matrix = sparse.BCOO.fromdense(out_matrix)
+    return out_matrix
+
+
+def annihilation_op(N, dtype=jnp.complex64, use_sparse=True):
+    """
+    Outputs matrix representation of Ladder Operator in Fock Basis
+    """
+    if not isinstance(N, int):
+        raise ValueError("N must be of int type and non-zero")
+
+    out_matrix = jnp.diag(jnp.sqrt(jnp.arange(1, N, dtype=dtype)), k=1)
+    if use_sparse:
+        out_matrix = sparse.BCOO.fromdense(out_matrix)
+    return out_matrix
+
+
+def creation_op(N, dtype=jnp.complex64, use_sparse=True):
+    """
+    Outputs matrix representation of Ladder Operator in Fock Basis
+    """
+    if not isinstance(N, int):
+        raise ValueError("N must be of int type and non-zero")
+
+    out_matrix = jnp.diag(jnp.sqrt(jnp.arange(1, N, dtype=dtype)), k=-1)
+    if use_sparse:
+        out_matrix = sparse.BCOO.fromdense(out_matrix)
+    return out_matrix
+
+
+def q_eye(N, dtype=jnp.complex64, use_sparse=True):
+    """
+    Outputs matrix representation of Ladder Operator in Fock Basis
+    """
+    if not isinstance(N, int):
+        raise ValueError("N must be of int type and non-zero")
+
+    out_matrix = jnp.identity(N, dtype=dtype)
+    if use_sparse:
+        out_matrix = sparse.BCOO.fromdense(out_matrix)
+    return out_matrix
+
+
+def handle_diffrax_stats(stats, name="Solution"):
+    max_steps = stats["max_steps"][0]
+    num_accepted_steps = stats["num_accepted_steps"][0]
+    num_rejected_steps = stats["num_rejected_steps"][0]
+    num_steps = stats["num_steps"][0]
+    print(f"{name} Statistics")
+    print(f"max_steps: {max_steps}")
+    print(f"num_accepted_steps: {num_accepted_steps}")
+    print(f"num_rejected_steps: {num_rejected_steps}")
+    print(f"num_steps: {num_steps}")
